{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Evaluation of ArXiv Hybrid Search System\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook evaluates the performance of three different search methods on the ArXiv paper dataset:\\n\",\n",
    "    \"1.  **Keyword-only Search**: Using SQLite FTS5.\\n\",\n",
    "    \"2.  **Vector-only Search**: Using FAISS for semantic similarity.\\n\",\n",
    "    \"3.  **Hybrid Search**: Combining keyword and vector search results using Reciprocal Rank Fusion (RRF).\\n\",\n",
    "    \"\\n\",\n",
    "    \"The primary metric used is **Recall@3**, which measures how often a known relevant document appears in the top 3 search results.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Setup\\n\",\n",
    "    \"\\n\",\n",
    "    \"First, we import the necessary libraries and define the `ArxivSearch` class, which encapsulates all the search functionalities.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sqlite3\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import faiss\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from sentence_transformers import SentenceTransformer\\n\",\n",
    "    \"import logging\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Configuration ---\\n\",\n",
    "    \"DB_PATH = \\\"arxiv_data.db\\\"\\n\",\n",
    "    \"FAISS_INDEX_PATH = \\\"arxiv_faiss.index\\\"\\n\",\n",
    "    \"EMBEDDING_MODEL = 'all-MiniLM-L6-v2'\\n\",\n",
    "    \"DIMENSION = 384\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Logging ---\\n\",\n",
    "    \"logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\\n\",\n",
    "    \"\\n\",\n",
    "    \"class ArxivSearch:\\n\",\n",
    "    \"    def __init__(self):\\n\",\n",
    "    \"        self.conn = sqlite3.connect(DB_PATH)\\n\",\n",
    "    \"        self.model = SentenceTransformer(EMBEDDING_MODEL)\\n\",\n",
    "    \"        self.index = None\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            self.index = faiss.read_index(FAISS_INDEX_PATH)\\n\",\n",
    "    \"            logging.info(\\\"FAISS index loaded successfully.\\\")\\n\",\n",
    "    \"        except RuntimeError:\\n\",\n",
    "    \"            logging.error(f\\\"Could not load FAISS index from {FAISS_INDEX_PATH}. Please ensure the index file exists.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def keyword_search(self, query, k=3):\\n\",\n",
    "    \"        c = self.conn.cursor()\\n\",\n",
    "    \"        c.execute(\\\"\\\"\\\"\\n\",\n",
    "    \"            SELECT documents.doc_id, documents.title, doc_chunks.content, rank\\n\",\n",
    "    \"            FROM doc_chunks\\n\",\n",
    "    \"            JOIN documents ON doc_chunks.doc_id = documents.doc_id\\n\",\n",
    "    \"            WHERE doc_chunks MATCH ?\\n\",\n",
    "    \"            ORDER BY rank\\n\",\n",
    "    \"            LIMIT ?\\n\",\n",
    "    \"        \\\"\\\"\\\", (query, k))\\n\",\n",
    "    \"        return c.fetchall()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def vector_search(self, query, k=3):\\n\",\n",
    "    \"        if self.index is None:\\n\",\n",
    "    \"            return []\\n\",\n",
    "    \"        query_embedding = self.model.encode([query])\\n\",\n",
    "    \"        distances, indices = self.index.search(query_embedding, k)\\n\",\n",
    "    \"        results = []\\n\",\n",
    "    \"        c = self.conn.cursor()\\n\",\n",
    "    \"        for i in range(k):\\n\",\n",
    "    \"            c.execute(\\\"\\\"\\\"\\n\",\n",
    "    \"                SELECT documents.doc_id, documents.title, doc_chunks.content\\n\",\n",
    "    \"                FROM doc_chunks\\n\",\n",
    "    \"                JOIN documents ON doc_chunks.doc_id = documents.doc_id\\n\",\n",
    "    \"                WHERE doc_chunks.rowid = ?\\n\",\n",
    "    \"            \\\"\\\"\\\", (int(indices[0][i]) + 1,))\\n\",\n",
    "    \"            result = c.fetchone()\\n\",\n",
    "    \"            if result:\\n\",\n",
    "    \"                results.append(result + (distances[0][i],))\\n\",\n",
    "    \"        return results\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def hybrid_search(self, query, k=3, alpha=0.5):\\n\",\n",
    "    \"        keyword_results = self.keyword_search(query, k)\\n\",\n",
    "    \"        vector_results = self.vector_search(query, k)\\n\",\n",
    "    \"        ranked_list = {}\\n\",\n",
    "    \"        for i, (doc_id, _, content, _) in enumerate(keyword_results):\\n\",\n",
    "    \"            if (doc_id, content) not in ranked_list:\\n\",\n",
    "    \"                ranked_list[(doc_id, content)] = 0\\n\",\n",
    "    \"            ranked_list[(doc_id, content)] += 1 / (i + 1)\\n\",\n",
    "    \"        for i, (doc_id, _, content, _) in enumerate(vector_results):\\n\",\n",
    "    \"            if (doc_id, content) not in ranked_list:\\n\",\n",
    "    \"                ranked_list[(doc_id, content)] = 0\\n\",\n",
    "    \"            ranked_list[(doc_id, content)] += alpha * (1 / (i + 1))\\n\",\n",
    "    \"        sorted_results = sorted(ranked_list.items(), key=lambda item: item[1], reverse=True)\\n\",\n",
    "    \"        final_results = []\\n\",\n",
    "    \"        for (doc_id, content), score in sorted_results[:k]:\\n\",\n",
    "    \"            c = self.conn.cursor()\\n\",\n",
    "    \"            c.execute(\\\"SELECT title FROM documents WHERE doc_id = ?\\\", (doc_id,))\\n\",\n",
    "    \"            title = c.fetchone()[0]\\n\",\n",
    "    \"            final_results.append({\\\"doc_id\\\": doc_id, \\\"title\\\": title, \\\"content\\\": content, \\\"score\\\": score})\\n\",\n",
    "    \"        return final_results\\n\",\n",
    "    \"\\n\",\n",
    "    \"search_system = ArxivSearch()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Test Queries\\n\",\n",
    "    \"\\n\",\n",
    "    \"We define a set of 10 test queries with known relevant document IDs to evaluate the search methods.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"test_queries = [\\n\",\n",
    "    \"    {\\\"query\\\": \\\"transformer models for speech\\\", \\\"relevant_doc_ids\\\": {3}},\\n\",\n",
    "    \"    {\\\"query\\\": \\\"large language model security\\\", \\\"relevant_doc_ids\\\": {4}},\\n\",\n",
    "    \"    {\\\"query\\\": \\\"reinforcement learning for robotics\\\", \\\"relevant_doc_ids\\\": {10}},\\n\",\n",
    "    \"    {\\\"query\\\": \\\"multi-agent systems\\\", \\\"relevant_doc_ids\\\": {4, 11}},\\n\",\n",
    "    \"    {\\\"query\\\": \\\"sentiment analysis in social media\\\", \\\"relevant_doc_ids\\\": {12}},\\n\",\n",
    "    \"    {\\\"query\\\": \\\"knowledge distillation in NLP\\\", \\\"relevant_doc_ids\\\": {13}},\\n\",\n",
    "    \"    {\\\"query\\\": \\\"vision-language models\\\", \\\"relevant_doc_ids\\\": {13, 14}},\\n\",\n",
    "    \"    {\\\"query\\\": \\\"causal inference in machine learning\\\", \\\"relevant_doc_ids\\\": {10}},\\n\",\n",
    "    \"    {\\\"query\\\": \\\"graph neural networks for heterogeneous graphs\\\", \\\"relevant_doc_ids\\\": {15}},\\n\",\n",
    "    \"    {\\\"query\\\": \\\"conformal prediction for uncertainty\\\", \\\"relevant_doc_ids\\\": {16}}\\n\",\n",
    "    \"]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Evaluation\\n\",\n",
    "    \"\\n\",\n",
    "    \"We now run the evaluation loop. For each query, we perform keyword, vector, and hybrid searches and check if any of the top 3 results match the known relevant documents. We then calculate the Recall@3 for each method.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def run_evaluation(k=3):\\n\",\n",
    "    \"    metrics = {\\n\",\n",
    "    \"        \\\"Keyword-Only\\\": {\\\"hits\\\": 0, f\\\"recall@{k}\\\": 0},\\n\",\n",
    "    \"        \\\"Vector-Only\\\": {\\\"hits\\\": 0, f\\\"recall@{k}\\\": 0},\\n\",\n",
    "    \"        \\\"Hybrid\\\": {\\\"hits\\\": 0, f\\\"recall@{k}\\\": 0}\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for item in test_queries:\\n\",\n",
    "    \"        query = item[\\\"query\\\"]\\n\",\n",
    "    \"        relevant_ids = item[\\\"relevant_doc_ids\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Keyword search\\n\",\n",
    "    \"        keyword_results = search_system.keyword_search(query, k)\\n\",\n",
    "    \"        retrieved_ids = {res[0] for res in keyword_results}\\n\",\n",
    "    \"        if relevant_ids.intersection(retrieved_ids):\\n\",\n",
    "    \"            metrics[\\\"Keyword-Only\\\"][\\\"hits\\\"] += 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Vector search\\n\",\n",
    "    \"        vector_results = search_system.vector_search(query, k)\\n\",\n",
    "    \"        retrieved_ids = {res[0] for res in vector_results}\\n\",\n",
    "    \"        if relevant_ids.intersection(retrieved_ids):\\n\",\n",
    "    \"            metrics[\\\"Vector-Only\\\"][\\\"hits\\\"] += 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Hybrid search\\n\",\n",
    "    \"        hybrid_results = search_system.hybrid_search(query, k)\\n\",\n",
    "    \"        retrieved_ids = {res[\\\"doc_id\\\"] for res in hybrid_results}\\n\",\n",
    "    \"        if relevant_ids.intersection(retrieved_ids):\\n\",\n",
    "    \"            metrics[\\\"Hybrid\\\"][\\\"hits\\\"] += 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"    num_queries = len(test_queries)\\n\",\n",
    "    \"    for method in metrics:\\n\",\n",
    "    \"        metrics[method][f\\\"recall@{k}\\\"] = metrics[method][\\\"hits\\\"] / num_queries\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return metrics\\n\",\n",
    "    \"\\n\",\n",
    "    \"evaluation_results = run_evaluation(k=3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Print results as a DataFrame\\n\",\n",
    "    \"df = pd.DataFrame(evaluation_results).T\\n\",\n",
    "    \"print(\\\"Evaluation Results (Recall@3):\\\")\\n\",\n",
    "    \"print(df)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Visualization\\n\",\n",
    "    \"\\n\",\n",
    "    \"Finally, we visualize the Recall@3 scores for each search method to compare their performance.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"recall_scores = {method: data['recall@3'] for method, data in evaluation_results.items()}\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig, ax = plt.subplots(figsize=(10, 6))\\n\",\n",
    "    \"ax.bar(recall_scores.keys(), recall_scores.values(), color=['#4c72b0', '#55a868', '#c44e52'])\\n\",\n",
    "    \"ax.set_ylabel('Recall@3')\\n\",\n",
    "    \"ax.set_title('Comparison of Search Methods: Recall@3')\\n\",\n",
    "    \"ax.set_ylim(0, 1.0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, (method, score) in enumerate(recall_scores.items()):\\n\",\n",
    "    \"    ax.text(i, score + 0.02, f'{score:.2f}', ha='center', va='bottom')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Example Queries\\n\",\n",
    "    \"\\n\",\n",
    "    \"Here are the top 3 results for a few example queries using each search method.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def display_results(query, k=3):\\n\",\n",
    "    \"    print(f\\\"\\\\n--- Query: '{query}' ---\\\\n\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\n**Keyword-Only Search Results:**\\\")\\n\",\n",
    "    \"    keyword_res = search_system.keyword_search(query, k)\\n\",\n",
    "    \"    if keyword_res:\\n\",\n",
    "    \"        for i, (doc_id, title, content, rank) in enumerate(keyword_res):\\n\",\n",
    "    \"            print(f\\\"{i+1}. [Doc ID: {doc_id}] {title}\\\\n   Content: {content[:150]}...\\\\n\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"No results found.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"\\\\n**Vector-Only Search Results:**\\\")\\n\",\n",
    "    \"    vector_res = search_system.vector_search(query, k)\\n\",\n",
    "    \"    if vector_res:\\n\",\n",
    "    \"        for i, (doc_id, title, content, dist) in enumerate(vector_res):\\n\",\n",
    "    \"            print(f\\\"{i+1}. [Doc ID: {doc_id}] {title}\\\\n   Content: {content[:150]}...\\\\n\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"No results found.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"\\\\n**Hybrid Search Results:**\\\")\\n\",\n",
    "    \"    hybrid_res = search_system.hybrid_search(query, k)\\n\",\n",
    "    \"    if hybrid_res:\\n\",\n",
    "    \"        for i, res in enumerate(hybrid_res):\\n\",\n",
    "    \"            print(f\\\"{i+1}. [Doc ID: {res['doc_id']}] {res['title']}\\\\n   Content: {res['content'][:150]}...\\\\n\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"No results found.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display results for a few example queries\\n\",\n",
    "    \"display_results(\\\"large language model security\\\")\\n\",\n",
    "    \"display_results(\\\"reinforcement learning for robotics\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.12\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n"
   ],
   "id": "adc74504fec36790"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
